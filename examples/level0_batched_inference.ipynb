{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level 0: Batched MAP Shear Inference\n",
    "\n",
    "This notebook demonstrates SHINE's **Level 0 sanity check** on a batch of 10 galaxies\n",
    "sharing the same true shear. Level 0 is the noiseless self-consistency test: when data\n",
    "is generated by the exact same forward model with effectively zero noise, the MAP\n",
    "estimate should recover the truth exactly.\n",
    "\n",
    "All 10 galaxies are inferred **simultaneously** in a single batched MAP call using\n",
    "`build_batched_model()`, which vmaps the rendering over the batch dimension. This\n",
    "compiles the entire batch into one XLA program -- far more efficient than looping.\n",
    "\n",
    "Since there is no noise, MAP (point estimation) is the natural choice -- full MCMC\n",
    "is unnecessary and much slower.\n",
    "\n",
    "**Configuration:** Exponential galaxy (hlr=0.5\"), Gaussian PSF ($\\sigma$=0.382\"),\n",
    "pixel scale 0.263\"/px, noise $\\sigma = 10^{-6}$, true shear $g_1=0.01$, $g_2=0.00$.\n",
    "\n",
    "**What we do:**\n",
    "1. Generate 10 synthetic observations with the same shear\n",
    "2. Run **batched** MAP inference on all realizations simultaneously\n",
    "3. Check that MAP estimates match truth with negligible bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T17:22:51.241338Z",
     "iopub.status.busy": "2026-02-08T17:22:51.241213Z",
     "iopub.status.idle": "2026-02-08T17:22:53.402370Z",
     "shell.execute_reply": "2026-02-08T17:22:53.401841Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Workaround: XLA autotuner fails on tiny batched f64 GEMMs (2x2 Jacobian dot)\n",
    "# on some GPUs. Disabling autotuning selects a default kernel instead.\n",
    "os.environ.setdefault(\"XLA_FLAGS\", \"--xla_gpu_autotune_level=0\")\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz as az\n",
    "\n",
    "from shine.config import (\n",
    "    ShineConfig,\n",
    "    ImageConfig,\n",
    "    NoiseConfig,\n",
    "    PSFConfig,\n",
    "    GalaxyConfig,\n",
    "    ShearConfig,\n",
    "    EllipticityConfig,\n",
    "    PositionConfig,\n",
    "    InferenceConfig,\n",
    "    MAPConfig,\n",
    "    DistributionConfig,\n",
    ")\n",
    "from shine.scene import SceneBuilder\n",
    "from shine.inference import Inference\n",
    "from shine.validation.simulation import generate_batch_observations\n",
    "from shine.validation.extraction import (\n",
    "    extract_convergence_diagnostics,\n",
    "    extract_shear_estimates,\n",
    "    check_convergence,\n",
    ")\n",
    "from shine.validation.bias_config import ConvergenceThresholds\n",
    "from shine.validation.statistics import compute_bias_single_point\n",
    "\n",
    "# Use 64-bit precision for accurate shear recovery\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "print(f\"JAX devices: {jax.devices()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "Parameters matched to the [ngmix metacal example](https://github.com/esheldon/ngmix/blob/master/examples/metacal/metacal.py):\n",
    "- **Galaxy**: Exponential, hlr=0.5\" (metacal `gal_hlr=0.5`)\n",
    "- **PSF**: Gaussian, $\\sigma = 0.382\"$ (equivalent to Moffat FWHM=0.9\")\n",
    "- **Pixel scale**: 0.263\"/px (metacal `scale=0.263`)\n",
    "- **Noise**: $\\sigma = 10^{-6}$ (metacal default `noise=1e-6`)\n",
    "- **Shear**: $g_1 = 0.01$, $g_2 = 0.00$ (metacal `shear_true=[0.01, 0.00]`)\n",
    "- **Position**: Fixed at center (metacal uses random subpixel offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T17:22:53.426580Z",
     "iopub.status.busy": "2026-02-08T17:22:53.426279Z",
     "iopub.status.idle": "2026-02-08T17:22:53.430952Z",
     "shell.execute_reply": "2026-02-08T17:22:53.430541Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ground truth shear (matches metacal shear_true=[0.01, 0.00])\n",
    "G1_TRUE = 0.01\n",
    "G2_TRUE = 0.00\n",
    "N_BATCH = 10\n",
    "\n",
    "config = ShineConfig(\n",
    "    image=ImageConfig(\n",
    "        pixel_scale=0.263,       # arcsec/pixel (metacal scale=0.263)\n",
    "        size_x=48,\n",
    "        size_y=48,\n",
    "        n_objects=1,\n",
    "        fft_size=128,\n",
    "        noise=NoiseConfig(type=\"Gaussian\", sigma=1e-6),  # metacal noise=1e-6\n",
    "    ),\n",
    "    psf=PSFConfig(\n",
    "        type=\"Gaussian\",\n",
    "        sigma=0.382,             # arcsec (equivalent to Moffat FWHM=0.9: 0.9/2.355)\n",
    "    ),\n",
    "    gal=GalaxyConfig(\n",
    "        type=\"Exponential\",      # metacal galsim.Exponential\n",
    "        flux=1.0,                # metacal default flux=1\n",
    "        half_light_radius=0.5,   # arcsec (metacal gal_hlr=0.5)\n",
    "        ellipticity=EllipticityConfig(type=\"E1E2\", e1=0.0, e2=0.0),\n",
    "        shear=ShearConfig(\n",
    "            type=\"G1G2\",\n",
    "            g1=DistributionConfig(type=\"Normal\", mean=0.0, sigma=0.05),\n",
    "            g2=DistributionConfig(type=\"Normal\", mean=0.0, sigma=0.05),\n",
    "        ),\n",
    "        position=PositionConfig(\n",
    "            type=\"Uniform\",\n",
    "            x_min=23.5, x_max=24.5,\n",
    "            y_min=23.5, y_max=24.5,\n",
    "        ),\n",
    "    ),\n",
    "    inference=InferenceConfig(\n",
    "        method=\"map\",\n",
    "        map_config=MAPConfig(num_steps=200, learning_rate=0.1),\n",
    "        rng_seed=42,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(f\"Image: {config.image.size_x}x{config.image.size_y} px, \"\n",
    "      f\"scale={config.image.pixel_scale}\\\"/px\")\n",
    "print(f\"Galaxy: {config.gal.type}, flux={config.gal.flux}, \"\n",
    "      f\"hlr={config.gal.half_light_radius}\\\"\")\n",
    "print(f\"PSF: {config.psf.type}, sigma={config.psf.sigma}\\\"\")\n",
    "print(f\"Noise sigma: {config.image.noise.sigma}\")\n",
    "print(f\"True shear: g1={G1_TRUE}, g2={G2_TRUE}\")\n",
    "print(f\"Batch size: {N_BATCH}\")\n",
    "print(f\"Inference method: {config.inference.method}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Observations\n",
    "\n",
    "All 10 galaxies share the same true shear but have independent (effectively zero) noise\n",
    "realizations. We use `generate_batch_observations()` to generate and stack all images\n",
    "into a single `(N_BATCH, nx, ny)` array with a shared PSF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T17:22:53.432291Z",
     "iopub.status.busy": "2026-02-08T17:22:53.432127Z",
     "iopub.status.idle": "2026-02-08T17:22:53.594049Z",
     "shell.execute_reply": "2026-02-08T17:22:53.593593Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate N_BATCH observations with the same true shear, stacked into a batch\n",
    "seeds = list(range(100, 100 + N_BATCH))\n",
    "shear_pairs = [(G1_TRUE, G2_TRUE)] * N_BATCH\n",
    "\n",
    "batch_sim = generate_batch_observations(\n",
    "    config, shear_pairs=shear_pairs, seeds=seeds, run_id_prefix=\"level0\"\n",
    ")\n",
    "\n",
    "print(f\"Generated {N_BATCH} observations\")\n",
    "print(f\"Stacked image shape: {batch_sim.images.shape}\")\n",
    "print(f\"PSF type: {type(batch_sim.psf_model).__name__}\")\n",
    "print(f\"Run IDs: {batch_sim.run_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T17:22:53.595405Z",
     "iopub.status.busy": "2026-02-08T17:22:53.595300Z",
     "iopub.status.idle": "2026-02-08T17:22:53.865521Z",
     "shell.execute_reply": "2026-02-08T17:22:53.865008Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize a few of the generated images\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    im = ax.imshow(batch_sim.images[i], origin=\"lower\", cmap=\"gray_r\")\n",
    "    ax.set_title(f\"Galaxy {i}\", fontsize=10)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "fig.suptitle(\n",
    "    f\"Level 0: 10 Exponential galaxies, g1={G1_TRUE}, g2={G2_TRUE}, \"\n",
    "    f\"noise={config.image.noise.sigma}\",\n",
    "    fontsize=12,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Batched MAP Inference\n",
    "\n",
    "Instead of looping over realizations, we use `build_batched_model()` which creates\n",
    "a single NumPyro model with a `plate(\"batch\", N_BATCH)` over all parameters and\n",
    "vmaps the rendering. This compiles to one XLA program and runs all 10 galaxies in\n",
    "parallel on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T17:22:53.866957Z",
     "iopub.status.busy": "2026-02-08T17:22:53.866843Z",
     "iopub.status.idle": "2026-02-08T17:23:07.321484Z",
     "shell.execute_reply": "2026-02-08T17:23:07.320964Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build batched model and run a single MAP inference over all realizations\n",
    "import time\n",
    "\n",
    "scene = SceneBuilder(config)\n",
    "model_fn = scene.build_batched_model(N_BATCH)\n",
    "\n",
    "map_cfg = config.inference.map_config\n",
    "print(f\"Inference method: {config.inference.method}\")\n",
    "print(f\"MAP: {map_cfg.num_steps} steps, lr={map_cfg.learning_rate}\")\n",
    "print(f\"Batch size: {N_BATCH}\\n\")\n",
    "\n",
    "rng_key = jax.random.PRNGKey(config.inference.rng_seed)\n",
    "engine = Inference(model=model_fn, config=config.inference)\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "batched_estimates = engine.run_map(\n",
    "    rng_key=rng_key,\n",
    "    observed_data=batch_sim.images,\n",
    "    extra_args={\"psf\": batch_sim.psf_model},\n",
    "    map_config=map_cfg,\n",
    ")\n",
    "elapsed = time.perf_counter() - t0\n",
    "\n",
    "print(f\"\\nBatched MAP completed in {elapsed:.2f} s\")\n",
    "for k, v in batched_estimates.items():\n",
    "    print(f\"  {k}: shape={np.array(v).shape}\")\n",
    "\n",
    "# Split batched MAP estimates into per-realization InferenceData objects.\n",
    "# We do this manually because _map_estimates_to_idata + split_batched_idata\n",
    "# doesn't work for MAP: ArviZ names the batch dim \"g1_dim_0\" not \"batch\".\n",
    "run_ids = batch_sim.run_ids\n",
    "idata_list = []\n",
    "for i in range(N_BATCH):\n",
    "    single = {}\n",
    "    for k, v in batched_estimates.items():\n",
    "        arr = np.atleast_1d(np.array(v))\n",
    "        single[k] = arr[i] if arr.ndim >= 1 and arr.shape[0] == N_BATCH else arr\n",
    "    idata = Inference._map_estimates_to_idata(single)\n",
    "    idata_list.append(idata)\n",
    "\n",
    "# Print per-realization MAP estimates\n",
    "for i, run_id in enumerate(run_ids):\n",
    "    g1_val = float(idata_list[i].posterior.g1.values.flatten()[0])\n",
    "    g2_val = float(idata_list[i].posterior.g2.values.flatten()[0])\n",
    "    print(f\"  {run_id}: g1={g1_val:+.6f}, g2={g2_val:+.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extract Estimates\n",
    "\n",
    "For each realization, extract the MAP point estimates and check that they\n",
    "match the truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T17:23:07.322796Z",
     "iopub.status.busy": "2026-02-08T17:23:07.322698Z",
     "iopub.status.idle": "2026-02-08T17:23:07.325495Z",
     "shell.execute_reply": "2026-02-08T17:23:07.324997Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Created {N_BATCH} per-realization InferenceData objects from batched MAP\")\n",
    "print(f\"Run IDs: {run_ids}\")\n",
    "print(f\"Example: {run_ids[0]}, posterior vars: {list(idata_list[0].posterior.data_vars)}\")\n",
    "print(f\"  inference_method: {idata_list[0].posterior.attrs.get('inference_method')}\")\n",
    "print(f\"  g1 shape: {idata_list[0].posterior.g1.values.shape}\")\n",
    "print(f\"  g2 shape: {idata_list[0].posterior.g2.values.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extract Diagnostics\n",
    "\n",
    "For each realization, extract:\n",
    "- **Shear estimates**: MAP point estimate (mean = median = value, std = 0)\n",
    "- **Convergence diagnostics**: sentinel values for MAP (rhat=1, ess=1)\n",
    "\n",
    "Level 0 acceptance criterion for MAP: the estimate should be very close to truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T17:23:07.326656Z",
     "iopub.status.busy": "2026-02-08T17:23:07.326522Z",
     "iopub.status.idle": "2026-02-08T17:23:07.333989Z",
     "shell.execute_reply": "2026-02-08T17:23:07.333589Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract results for all realizations\n",
    "results = []\n",
    "for run_id, single_idata in zip(run_ids, idata_list):\n",
    "    g1_est = extract_shear_estimates(single_idata, \"g1\")\n",
    "    g2_est = extract_shear_estimates(single_idata, \"g2\")\n",
    "    diag = extract_convergence_diagnostics(single_idata)\n",
    "    method = single_idata.posterior.attrs.get(\"inference_method\", \"nuts\")\n",
    "    passed = check_convergence(diag, ConvergenceThresholds(), method=method)\n",
    "    results.append({\n",
    "        \"run_id\": run_id,\n",
    "        \"g1_est\": g1_est,\n",
    "        \"g2_est\": g2_est,\n",
    "        \"diagnostics\": diag,\n",
    "        \"passed\": passed,\n",
    "    })\n",
    "\n",
    "# Summary table\n",
    "print(f\"{'Run ID':<14} {'g1 estimate':>14} {'g2 estimate':>14} {'Pass':>5}\")\n",
    "print(\"-\" * 55)\n",
    "for r in results:\n",
    "    print(\n",
    "        f\"{r['run_id']:<14} \"\n",
    "        f\"{r['g1_est'].mean:>14.6f} \"\n",
    "        f\"{r['g2_est'].mean:>14.6f} \"\n",
    "        f\"{'OK' if r['passed'] else 'FAIL':>5}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Acceptance Criteria Check\n",
    "\n",
    "For Level 0 MAP, each realization must satisfy:\n",
    "1. MAP estimate close to truth (absolute offset $< 10^{-3}$)\n",
    "2. Convergence always passes for MAP (no sampling diagnostics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T17:23:07.335278Z",
     "iopub.status.busy": "2026-02-08T17:23:07.335177Z",
     "iopub.status.idle": "2026-02-08T17:23:07.338897Z",
     "shell.execute_reply": "2026-02-08T17:23:07.338568Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_ABS_OFFSET = 1e-3\n",
    "\n",
    "all_passed = True\n",
    "print(\"Level 0 Acceptance Criteria (MAP)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for r in results:\n",
    "    run_id = r[\"run_id\"]\n",
    "    g1, g2 = r[\"g1_est\"], r[\"g2_est\"]\n",
    "\n",
    "    # For MAP: check absolute offset from truth\n",
    "    g1_offset = abs(g1.mean - G1_TRUE)\n",
    "    g2_offset = abs(g2.mean - G2_TRUE)\n",
    "    offset_ok = g1_offset < MAX_ABS_OFFSET and g2_offset < MAX_ABS_OFFSET\n",
    "\n",
    "    passed = offset_ok and r[\"passed\"]\n",
    "    all_passed = all_passed and passed\n",
    "\n",
    "    status = \"PASS\" if passed else \"FAIL\"\n",
    "    print(f\"\\n{run_id} [{status}]\")\n",
    "    print(f\"  g1: truth={G1_TRUE:+.4f}  MAP={g1.mean:+.6f}  \"\n",
    "          f\"|offset|={g1_offset:.2e}  {'ok' if g1_offset < MAX_ABS_OFFSET else 'FAIL'}\")\n",
    "    print(f\"  g2: truth={G2_TRUE:+.4f}  MAP={g2.mean:+.6f}  \"\n",
    "          f\"|offset|={g2_offset:.2e}  {'ok' if g2_offset < MAX_ABS_OFFSET else 'FAIL'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"Overall Level 0 result: {'ALL PASSED' if all_passed else 'SOME FAILED'}\")\n",
    "print(f\"  {sum(1 for r in results if r['passed'])}/{len(results)} \"\n",
    "      f\"realizations passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Multiplicative Bias\n",
    "\n",
    "For each realization, compute the multiplicative bias:\n",
    "$$m = \\frac{\\bar{g}_{\\rm est}}{g_{\\rm true}} - 1$$\n",
    "\n",
    "At Level 0 (noiseless, self-consistent model), we expect $m \\approx 0$.\n",
    "\n",
    "Since $g_2^{\\rm true} = 0$ (matching metacal), we cannot compute $m$ for $g_2$\n",
    "(division by zero). Instead we report the additive residual $c_2 = \\bar{g}_2 - 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T17:23:07.340444Z",
     "iopub.status.busy": "2026-02-08T17:23:07.340338Z",
     "iopub.status.idle": "2026-02-08T17:23:07.343875Z",
     "shell.execute_reply": "2026-02-08T17:23:07.343490Z"
    }
   },
   "outputs": [],
   "source": [
    "bias_g1_list = []\n",
    "\n",
    "print(f\"{'Run ID':<14} {'m(g1)':>12} {'c(g2)':>12}\")\n",
    "print(\"-\" * 42)\n",
    "\n",
    "for r in results:\n",
    "    b1 = compute_bias_single_point(G1_TRUE, r[\"g1_est\"].mean, r[\"g1_est\"].std, \"g1\")\n",
    "    bias_g1_list.append(b1)\n",
    "    # g2_true=0 so we report additive residual instead of multiplicative bias\n",
    "    c2 = r[\"g2_est\"].mean - G2_TRUE\n",
    "    print(f\"{r['run_id']:<14} {b1.m:>12.6f} {c2:>12.2e}\")\n",
    "\n",
    "# Ensemble average\n",
    "m_g1_vals = np.array([b.m for b in bias_g1_list])\n",
    "c_g2_vals = np.array([r[\"g2_est\"].mean - G2_TRUE for r in results])\n",
    "print(\"-\" * 42)\n",
    "print(f\"{'Ensemble mean':<14} {m_g1_vals.mean():>12.6f} {c_g2_vals.mean():>12.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Diagnostic Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T17:23:07.345185Z",
     "iopub.status.busy": "2026-02-08T17:23:07.345068Z",
     "iopub.status.idle": "2026-02-08T17:23:07.819508Z",
     "shell.execute_reply": "2026-02-08T17:23:07.818908Z"
    }
   },
   "outputs": [],
   "source": [
    "# Collect all g1, g2 MAP estimates\n",
    "g1_means = np.array([r[\"g1_est\"].mean for r in results])\n",
    "g2_means = np.array([r[\"g2_est\"].mean for r in results])\n",
    "indices = np.arange(N_BATCH)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# g1 estimates\n",
    "axes[0].scatter(indices, g1_means, marker=\"o\", s=60, color=\"steelblue\",\n",
    "                zorder=5, label=\"MAP estimate\")\n",
    "axes[0].axhline(G1_TRUE, color=\"red\", ls=\"--\", lw=2, label=f\"Truth = {G1_TRUE}\")\n",
    "axes[0].fill_between([-0.5, N_BATCH - 0.5],\n",
    "                     G1_TRUE - MAX_ABS_OFFSET,\n",
    "                     G1_TRUE + MAX_ABS_OFFSET,\n",
    "                     color=\"red\", alpha=0.1, label=f\"$\\\\pm${MAX_ABS_OFFSET}\")\n",
    "axes[0].set_xlabel(\"Realization\")\n",
    "axes[0].set_ylabel(\"$g_1$\")\n",
    "axes[0].set_title(\"$g_1$ Recovery (MAP)\")\n",
    "axes[0].legend(fontsize=9)\n",
    "axes[0].set_xticks(indices)\n",
    "\n",
    "# g2 estimates\n",
    "axes[1].scatter(indices, g2_means, marker=\"o\", s=60, color=\"coral\",\n",
    "                zorder=5, label=\"MAP estimate\")\n",
    "axes[1].axhline(G2_TRUE, color=\"red\", ls=\"--\", lw=2, label=f\"Truth = {G2_TRUE}\")\n",
    "axes[1].fill_between([-0.5, N_BATCH - 0.5],\n",
    "                     G2_TRUE - MAX_ABS_OFFSET,\n",
    "                     G2_TRUE + MAX_ABS_OFFSET,\n",
    "                     color=\"red\", alpha=0.1, label=f\"$\\\\pm${MAX_ABS_OFFSET}\")\n",
    "axes[1].set_xlabel(\"Realization\")\n",
    "axes[1].set_ylabel(\"$g_2$\")\n",
    "axes[1].set_title(\"$g_2$ Recovery (MAP)\")\n",
    "axes[1].legend(fontsize=9)\n",
    "axes[1].set_xticks(indices)\n",
    "\n",
    "fig.suptitle(\"Level 0: MAP Shear Recovery Across 10 Realizations\", fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T17:23:07.820874Z",
     "iopub.status.busy": "2026-02-08T17:23:07.820764Z",
     "iopub.status.idle": "2026-02-08T17:23:08.022555Z",
     "shell.execute_reply": "2026-02-08T17:23:08.022075Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bias plots: m(g1) and c(g2)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# g1: multiplicative bias\n",
    "axes[0].scatter(indices, m_g1_vals, marker=\"s\", s=60, color=\"steelblue\")\n",
    "axes[0].axhline(0, color=\"red\", ls=\"--\", lw=2, label=\"$m = 0$ (no bias)\")\n",
    "axes[0].axhline(m_g1_vals.mean(), color=\"green\", ls=\":\", lw=1.5,\n",
    "                label=f\"Mean $m$ = {m_g1_vals.mean():.2e}\")\n",
    "axes[0].set_xlabel(\"Realization\")\n",
    "axes[0].set_ylabel(\"$m_{g_1}$\")\n",
    "axes[0].set_title(\"Multiplicative Bias $g_1$\")\n",
    "axes[0].legend(fontsize=9)\n",
    "axes[0].set_xticks(indices)\n",
    "\n",
    "# g2: additive bias (g2_true = 0)\n",
    "axes[1].scatter(indices, c_g2_vals, marker=\"s\", s=60, color=\"coral\")\n",
    "axes[1].axhline(0, color=\"red\", ls=\"--\", lw=2, label=\"$c = 0$ (no bias)\")\n",
    "axes[1].axhline(c_g2_vals.mean(), color=\"green\", ls=\":\", lw=1.5,\n",
    "                label=f\"Mean $c$ = {c_g2_vals.mean():.2e}\")\n",
    "axes[1].set_xlabel(\"Realization\")\n",
    "axes[1].set_ylabel(\"$c_{g_2}$\")\n",
    "axes[1].set_title(\"Additive Bias $g_2$ ($g_2^{\\\\rm true} = 0$)\")\n",
    "axes[1].legend(fontsize=9)\n",
    "axes[1].set_xticks(indices)\n",
    "\n",
    "fig.suptitle(\"Level 0: Bias per Realization (MAP)\", fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T17:23:08.024261Z",
     "iopub.status.busy": "2026-02-08T17:23:08.024120Z",
     "iopub.status.idle": "2026-02-08T17:23:08.140854Z",
     "shell.execute_reply": "2026-02-08T17:23:08.140441Z"
    }
   },
   "outputs": [],
   "source": [
    "# g1 vs g2 MAP estimates across all realizations\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "ax.scatter(g1_means, g2_means, s=60, color=\"steelblue\", zorder=5, label=\"MAP estimates\")\n",
    "ax.scatter([G1_TRUE], [G2_TRUE], c=\"red\", s=150, marker=\"*\",\n",
    "           zorder=10, label=\"Truth\")\n",
    "ax.set_xlabel(\"$g_1$\")\n",
    "ax.set_ylabel(\"$g_2$\")\n",
    "ax.set_title(\"MAP Estimates: $g_1$ vs $g_2$\")\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "This Level 0 test validates that SHINE's forward model is **self-consistent**: when\n",
    "the data is generated from the same model with no noise, the MAP estimate recovers\n",
    "the true shear values with negligible bias.\n",
    "\n",
    "Since Level 0 is noiseless, MAP is the natural and fastest inference method --\n",
    "full MCMC is unnecessary. For higher validation levels (Level 1+) with realistic\n",
    "noise, NUTS or VI should be used instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T17:23:08.142711Z",
     "iopub.status.busy": "2026-02-08T17:23:08.142575Z",
     "iopub.status.idle": "2026-02-08T17:23:08.146220Z",
     "shell.execute_reply": "2026-02-08T17:23:08.145812Z"
    }
   },
   "outputs": [],
   "source": [
    "# Final summary\n",
    "n_passed = sum(1 for r in results if r[\"passed\"])\n",
    "\n",
    "print(\"Level 0 MAP Inference Summary\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  Batch size:           {N_BATCH}\")\n",
    "print(f\"  True shear:           g1={G1_TRUE}, g2={G2_TRUE}\")\n",
    "print(f\"  Inference method:     MAP\")\n",
    "print(f\"  All passed:           {n_passed}/{N_BATCH}\")\n",
    "print(f\"  Mean m(g1):           {m_g1_vals.mean():.2e}\")\n",
    "print(f\"  Mean c(g2):           {c_g2_vals.mean():.2e}\")\n",
    "print(f\"  Max |g1 offset|:      {max(abs(r['g1_est'].mean - G1_TRUE) for r in results):.2e}\")\n",
    "print(f\"  Max |g2 offset|:      {max(abs(r['g2_est'].mean - G2_TRUE) for r in results):.2e}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
