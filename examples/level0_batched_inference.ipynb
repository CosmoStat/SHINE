{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level 0: Batched MAP Shear Inference\n",
    "\n",
    "This notebook demonstrates SHINE's **Level 0 sanity check** on a batch of 10 galaxies\n",
    "sharing the same true shear. Level 0 is the noiseless self-consistency test: when data\n",
    "is generated by the exact same forward model with effectively zero noise, the MAP\n",
    "estimate should recover the truth exactly.\n",
    "\n",
    "Since there is no noise, MAP (point estimation) is the natural choice -- full MCMC\n",
    "is unnecessary and much slower.\n",
    "\n",
    "**Configuration:** Exponential galaxy (hlr=0.5\"), Moffat PSF ($\\beta$=2.5, FWHM=0.9\"),\n",
    "pixel scale 0.263\"/px, noise $\\sigma = 10^{-6}$, true shear $g_1=0.01$, $g_2=0.00$.\n",
    "\n",
    "**What we do:**\n",
    "1. Generate 10 synthetic observations with the same shear\n",
    "2. Run MAP inference on each realization independently\n",
    "3. Check that MAP estimates match truth with negligible bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz as az\n",
    "\n",
    "from shine.config import (\n",
    "    ShineConfig,\n",
    "    ImageConfig,\n",
    "    NoiseConfig,\n",
    "    PSFConfig,\n",
    "    GalaxyConfig,\n",
    "    ShearConfig,\n",
    "    EllipticityConfig,\n",
    "    PositionConfig,\n",
    "    InferenceConfig,\n",
    "    MAPConfig,\n",
    "    DistributionConfig,\n",
    ")\n",
    "from shine.scene import SceneBuilder\n",
    "from shine.inference import Inference\n",
    "from shine.validation.simulation import generate_biased_observation\n",
    "from shine.validation.extraction import (\n",
    "    extract_convergence_diagnostics,\n",
    "    extract_shear_estimates,\n",
    "    check_convergence,\n",
    ")\n",
    "from shine.validation.bias_config import ConvergenceThresholds\n",
    "from shine.validation.statistics import compute_bias_single_point\n",
    "\n",
    "# Use 64-bit precision for accurate shear recovery\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "print(f\"JAX devices: {jax.devices()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "Parameters matched to the [ngmix metacal example](https://github.com/esheldon/ngmix/blob/master/examples/metacal/metacal.py):\n",
    "- **Galaxy**: Exponential, hlr=0.5\" (metacal `gal_hlr=0.5`)\n",
    "- **PSF**: Moffat, $\\beta = 2.5$, FWHM=0.9\" (metacal `psf_fwhm=0.9, beta=2.5`)\n",
    "- **Pixel scale**: 0.263\"/px (metacal `scale=0.263`)\n",
    "- **Noise**: $\\sigma = 10^{-6}$ (metacal default `noise=1e-6`)\n",
    "- **Shear**: $g_1 = 0.01$, $g_2 = 0.00$ (metacal `shear_true=[0.01, 0.00]`)\n",
    "- **Position**: Fixed at center (metacal uses random subpixel offsets)\n",
    "\n",
    "**Note:** The metacal PSF has intrinsic ellipticity ($g_1^{\\rm PSF}=0.02$, $g_2^{\\rm PSF}=-0.01$).\n",
    "SHINE does not yet support PSF ellipticity, so we use a round Moffat PSF here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth shear (matches metacal shear_true=[0.01, 0.00])\n",
    "G1_TRUE = 0.01\n",
    "G2_TRUE = 0.00\n",
    "N_BATCH = 10\n",
    "\n",
    "config = ShineConfig(\n",
    "    image=ImageConfig(\n",
    "        pixel_scale=0.263,       # arcsec/pixel (metacal scale=0.263)\n",
    "        size_x=48,\n",
    "        size_y=48,\n",
    "        n_objects=1,\n",
    "        fft_size=128,\n",
    "        noise=NoiseConfig(type=\"Gaussian\", sigma=1e-6),  # metacal noise=1e-6\n",
    "    ),\n",
    "    psf=PSFConfig(\n",
    "        type=\"Moffat\",\n",
    "        sigma=0.9,               # FWHM in arcsec (metacal psf_fwhm=0.9)\n",
    "        beta=2.5,                # metacal beta=2.5\n",
    "    ),\n",
    "    gal=GalaxyConfig(\n",
    "        type=\"Exponential\",      # metacal galsim.Exponential\n",
    "        flux=1.0,                # metacal default flux=1\n",
    "        half_light_radius=0.5,   # arcsec (metacal gal_hlr=0.5)\n",
    "        ellipticity=EllipticityConfig(type=\"E1E2\", e1=0.0, e2=0.0),\n",
    "        shear=ShearConfig(\n",
    "            type=\"G1G2\",\n",
    "            g1=DistributionConfig(type=\"Normal\", mean=0.0, sigma=0.05),\n",
    "            g2=DistributionConfig(type=\"Normal\", mean=0.0, sigma=0.05),\n",
    "        ),\n",
    "        position=PositionConfig(\n",
    "            type=\"Uniform\",\n",
    "            x_min=23.5, x_max=24.5,\n",
    "            y_min=23.5, y_max=24.5,\n",
    "        ),\n",
    "    ),\n",
    "    inference=InferenceConfig(\n",
    "        method=\"map\",\n",
    "        map_config=MAPConfig(num_steps=200, learning_rate=0.1),\n",
    "        rng_seed=42,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(f\"Image: {config.image.size_x}x{config.image.size_y} px, \"\n",
    "      f\"scale={config.image.pixel_scale}\\\"/px\")\n",
    "print(f\"Galaxy: {config.gal.type}, flux={config.gal.flux}, \"\n",
    "      f\"hlr={config.gal.half_light_radius}\\\"\")\n",
    "print(f\"PSF: {config.psf.type}, FWHM={config.psf.sigma}\\\", beta={config.psf.beta}\")\n",
    "print(f\"Noise sigma: {config.image.noise.sigma}\")\n",
    "print(f\"True shear: g1={G1_TRUE}, g2={G2_TRUE}\")\n",
    "print(f\"Batch size: {N_BATCH}\")\n",
    "print(f\"Inference method: {config.inference.method}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Observations\n",
    "\n",
    "All 10 galaxies share the same true shear but have independent (effectively zero) noise\n",
    "realizations. We use `generate_biased_observation()` per realization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate N_BATCH independent observations with the same true shear\n",
    "seeds = list(range(100, 100 + N_BATCH))\n",
    "sim_results = []\n",
    "for seed in seeds:\n",
    "    sim = generate_biased_observation(config, G1_TRUE, G2_TRUE, seed)\n",
    "    sim_results.append(sim)\n",
    "\n",
    "print(f\"Generated {N_BATCH} observations\")\n",
    "print(f\"Image shape: {sim_results[0].observation.image.shape}\")\n",
    "print(f\"PSF type: {type(sim_results[0].observation.psf_model).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a few of the generated images\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    im = ax.imshow(sim_results[i].observation.image, origin=\"lower\", cmap=\"gray_r\")\n",
    "    ax.set_title(f\"Galaxy {i}\", fontsize=10)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "fig.suptitle(\n",
    "    f\"Level 0: 10 Exponential galaxies, g1={G1_TRUE}, g2={G2_TRUE}, \"\n",
    "    f\"noise={config.image.noise.sigma}\",\n",
    "    fontsize=12,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run MAP Inference\n",
    "\n",
    "For each realization, we build a model and run MAP estimation. Since Level 0\n",
    "is noiseless, MAP finds the maximum a posteriori point estimate which should\n",
    "match the truth exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run MAP inference for each realization\n",
    "scene = SceneBuilder(config)\n",
    "model_fn = scene.build_model()\n",
    "\n",
    "map_cfg = config.inference.map_config\n",
    "print(f\"Inference method: {config.inference.method}\")\n",
    "print(f\"MAP: {map_cfg.num_steps} steps, lr={map_cfg.learning_rate}\")\n",
    "\n",
    "idata_list = []\n",
    "for i, sim in enumerate(sim_results):\n",
    "    rng_key = jax.random.PRNGKey(config.inference.rng_seed + i)\n",
    "    engine = Inference(model=model_fn, config=config.inference)\n",
    "    idata = engine.run(\n",
    "        rng_key=rng_key,\n",
    "        observed_data=sim.observation.image,\n",
    "        extra_args={\"psf\": sim.observation.psf_model},\n",
    "    )\n",
    "    idata_list.append(idata)\n",
    "    g1_val = float(idata.posterior.g1.values.flatten()[0])\n",
    "    g2_val = float(idata.posterior.g2.values.flatten()[0])\n",
    "    print(f\"  Realization {i}: g1={g1_val:+.6f}, g2={g2_val:+.6f}\")\n",
    "\n",
    "print(f\"\\nCompleted {N_BATCH} MAP estimations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extract Estimates\n",
    "\n",
    "For each realization, extract the MAP point estimates and check that they\n",
    "match the truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ids = [f\"level0_{i:04d}\" for i in range(N_BATCH)]\n",
    "\n",
    "print(f\"Extracted {N_BATCH} MAP estimates\")\n",
    "print(f\"Example: {run_ids[0]}, posterior vars: {list(idata_list[0].posterior.data_vars)}\")\n",
    "print(f\"  inference_method: {idata_list[0].posterior.attrs.get('inference_method')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extract Diagnostics\n",
    "\n",
    "For each realization, extract:\n",
    "- **Shear estimates**: MAP point estimate (mean = median = value, std = 0)\n",
    "- **Convergence diagnostics**: sentinel values for MAP (rhat=1, ess=1)\n",
    "\n",
    "Level 0 acceptance criterion for MAP: the estimate should be very close to truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract results for all realizations\n",
    "results = []\n",
    "for run_id, single_idata in zip(run_ids, idata_list):\n",
    "    g1_est = extract_shear_estimates(single_idata, \"g1\")\n",
    "    g2_est = extract_shear_estimates(single_idata, \"g2\")\n",
    "    diag = extract_convergence_diagnostics(single_idata)\n",
    "    method = single_idata.posterior.attrs.get(\"inference_method\", \"nuts\")\n",
    "    passed = check_convergence(diag, ConvergenceThresholds(), method=method)\n",
    "    results.append({\n",
    "        \"run_id\": run_id,\n",
    "        \"g1_est\": g1_est,\n",
    "        \"g2_est\": g2_est,\n",
    "        \"diagnostics\": diag,\n",
    "        \"passed\": passed,\n",
    "    })\n",
    "\n",
    "# Summary table\n",
    "print(f\"{'Run ID':<14} {'g1 estimate':>14} {'g2 estimate':>14} {'Pass':>5}\")\n",
    "print(\"-\" * 55)\n",
    "for r in results:\n",
    "    print(\n",
    "        f\"{r['run_id']:<14} \"\n",
    "        f\"{r['g1_est'].mean:>14.6f} \"\n",
    "        f\"{r['g2_est'].mean:>14.6f} \"\n",
    "        f\"{'OK' if r['passed'] else 'FAIL':>5}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Acceptance Criteria Check\n",
    "\n",
    "For Level 0 MAP, each realization must satisfy:\n",
    "1. MAP estimate close to truth (absolute offset $< 10^{-3}$)\n",
    "2. Convergence always passes for MAP (no sampling diagnostics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ABS_OFFSET = 1e-3\n",
    "\n",
    "all_passed = True\n",
    "print(\"Level 0 Acceptance Criteria (MAP)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for r in results:\n",
    "    run_id = r[\"run_id\"]\n",
    "    g1, g2 = r[\"g1_est\"], r[\"g2_est\"]\n",
    "\n",
    "    # For MAP: check absolute offset from truth\n",
    "    g1_offset = abs(g1.mean - G1_TRUE)\n",
    "    g2_offset = abs(g2.mean - G2_TRUE)\n",
    "    offset_ok = g1_offset < MAX_ABS_OFFSET and g2_offset < MAX_ABS_OFFSET\n",
    "\n",
    "    passed = offset_ok and r[\"passed\"]\n",
    "    all_passed = all_passed and passed\n",
    "\n",
    "    status = \"PASS\" if passed else \"FAIL\"\n",
    "    print(f\"\\n{run_id} [{status}]\")\n",
    "    print(f\"  g1: truth={G1_TRUE:+.4f}  MAP={g1.mean:+.6f}  \"\n",
    "          f\"|offset|={g1_offset:.2e}  {'ok' if g1_offset < MAX_ABS_OFFSET else 'FAIL'}\")\n",
    "    print(f\"  g2: truth={G2_TRUE:+.4f}  MAP={g2.mean:+.6f}  \"\n",
    "          f\"|offset|={g2_offset:.2e}  {'ok' if g2_offset < MAX_ABS_OFFSET else 'FAIL'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"Overall Level 0 result: {'ALL PASSED' if all_passed else 'SOME FAILED'}\")\n",
    "print(f\"  {sum(1 for r in results if r['passed'])}/{len(results)} \"\n",
    "      f\"realizations passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Multiplicative Bias\n",
    "\n",
    "For each realization, compute the multiplicative bias:\n",
    "$$m = \\frac{\\bar{g}_{\\rm est}}{g_{\\rm true}} - 1$$\n",
    "\n",
    "At Level 0 (noiseless, self-consistent model), we expect $m \\approx 0$.\n",
    "\n",
    "Since $g_2^{\\rm true} = 0$ (matching metacal), we cannot compute $m$ for $g_2$\n",
    "(division by zero). Instead we report the additive residual $c_2 = \\bar{g}_2 - 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_g1_list = []\n",
    "\n",
    "print(f\"{'Run ID':<14} {'m(g1)':>12} {'c(g2)':>12}\")\n",
    "print(\"-\" * 42)\n",
    "\n",
    "for r in results:\n",
    "    b1 = compute_bias_single_point(G1_TRUE, r[\"g1_est\"].mean, r[\"g1_est\"].std, \"g1\")\n",
    "    bias_g1_list.append(b1)\n",
    "    # g2_true=0 so we report additive residual instead of multiplicative bias\n",
    "    c2 = r[\"g2_est\"].mean - G2_TRUE\n",
    "    print(f\"{r['run_id']:<14} {b1.m:>12.6f} {c2:>12.2e}\")\n",
    "\n",
    "# Ensemble average\n",
    "m_g1_vals = np.array([b.m for b in bias_g1_list])\n",
    "c_g2_vals = np.array([r[\"g2_est\"].mean - G2_TRUE for r in results])\n",
    "print(\"-\" * 42)\n",
    "print(f\"{'Ensemble mean':<14} {m_g1_vals.mean():>12.6f} {c_g2_vals.mean():>12.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Diagnostic Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all g1, g2 MAP estimates\n",
    "g1_means = np.array([r[\"g1_est\"].mean for r in results])\n",
    "g2_means = np.array([r[\"g2_est\"].mean for r in results])\n",
    "indices = np.arange(N_BATCH)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# g1 estimates\n",
    "axes[0].scatter(indices, g1_means, marker=\"o\", s=60, color=\"steelblue\",\n",
    "                zorder=5, label=\"MAP estimate\")\n",
    "axes[0].axhline(G1_TRUE, color=\"red\", ls=\"--\", lw=2, label=f\"Truth = {G1_TRUE}\")\n",
    "axes[0].fill_between([-0.5, N_BATCH - 0.5],\n",
    "                     G1_TRUE - MAX_ABS_OFFSET,\n",
    "                     G1_TRUE + MAX_ABS_OFFSET,\n",
    "                     color=\"red\", alpha=0.1, label=f\"$\\\\pm${MAX_ABS_OFFSET}\")\n",
    "axes[0].set_xlabel(\"Realization\")\n",
    "axes[0].set_ylabel(\"$g_1$\")\n",
    "axes[0].set_title(\"$g_1$ Recovery (MAP)\")\n",
    "axes[0].legend(fontsize=9)\n",
    "axes[0].set_xticks(indices)\n",
    "\n",
    "# g2 estimates\n",
    "axes[1].scatter(indices, g2_means, marker=\"o\", s=60, color=\"coral\",\n",
    "                zorder=5, label=\"MAP estimate\")\n",
    "axes[1].axhline(G2_TRUE, color=\"red\", ls=\"--\", lw=2, label=f\"Truth = {G2_TRUE}\")\n",
    "axes[1].fill_between([-0.5, N_BATCH - 0.5],\n",
    "                     G2_TRUE - MAX_ABS_OFFSET,\n",
    "                     G2_TRUE + MAX_ABS_OFFSET,\n",
    "                     color=\"red\", alpha=0.1, label=f\"$\\\\pm${MAX_ABS_OFFSET}\")\n",
    "axes[1].set_xlabel(\"Realization\")\n",
    "axes[1].set_ylabel(\"$g_2$\")\n",
    "axes[1].set_title(\"$g_2$ Recovery (MAP)\")\n",
    "axes[1].legend(fontsize=9)\n",
    "axes[1].set_xticks(indices)\n",
    "\n",
    "fig.suptitle(\"Level 0: MAP Shear Recovery Across 10 Realizations\", fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias plots: m(g1) and c(g2)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# g1: multiplicative bias\n",
    "axes[0].scatter(indices, m_g1_vals, marker=\"s\", s=60, color=\"steelblue\")\n",
    "axes[0].axhline(0, color=\"red\", ls=\"--\", lw=2, label=\"$m = 0$ (no bias)\")\n",
    "axes[0].axhline(m_g1_vals.mean(), color=\"green\", ls=\":\", lw=1.5,\n",
    "                label=f\"Mean $m$ = {m_g1_vals.mean():.2e}\")\n",
    "axes[0].set_xlabel(\"Realization\")\n",
    "axes[0].set_ylabel(\"$m_{g_1}$\")\n",
    "axes[0].set_title(\"Multiplicative Bias $g_1$\")\n",
    "axes[0].legend(fontsize=9)\n",
    "axes[0].set_xticks(indices)\n",
    "\n",
    "# g2: additive bias (g2_true = 0)\n",
    "axes[1].scatter(indices, c_g2_vals, marker=\"s\", s=60, color=\"coral\")\n",
    "axes[1].axhline(0, color=\"red\", ls=\"--\", lw=2, label=\"$c = 0$ (no bias)\")\n",
    "axes[1].axhline(c_g2_vals.mean(), color=\"green\", ls=\":\", lw=1.5,\n",
    "                label=f\"Mean $c$ = {c_g2_vals.mean():.2e}\")\n",
    "axes[1].set_xlabel(\"Realization\")\n",
    "axes[1].set_ylabel(\"$c_{g_2}$\")\n",
    "axes[1].set_title(\"Additive Bias $g_2$ ($g_2^{\\\\rm true} = 0$)\")\n",
    "axes[1].legend(fontsize=9)\n",
    "axes[1].set_xticks(indices)\n",
    "\n",
    "fig.suptitle(\"Level 0: Bias per Realization (MAP)\", fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g1 vs g2 MAP estimates across all realizations\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "ax.scatter(g1_means, g2_means, s=60, color=\"steelblue\", zorder=5, label=\"MAP estimates\")\n",
    "ax.scatter([G1_TRUE], [G2_TRUE], c=\"red\", s=150, marker=\"*\",\n",
    "           zorder=10, label=\"Truth\")\n",
    "ax.set_xlabel(\"$g_1$\")\n",
    "ax.set_ylabel(\"$g_2$\")\n",
    "ax.set_title(\"MAP Estimates: $g_1$ vs $g_2$\")\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "This Level 0 test validates that SHINE's forward model is **self-consistent**: when\n",
    "the data is generated from the same model with no noise, the MAP estimate recovers\n",
    "the true shear values with negligible bias.\n",
    "\n",
    "Since Level 0 is noiseless, MAP is the natural and fastest inference method --\n",
    "full MCMC is unnecessary. For higher validation levels (Level 1+) with realistic\n",
    "noise, NUTS or VI should be used instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "n_passed = sum(1 for r in results if r[\"passed\"])\n",
    "\n",
    "print(\"Level 0 MAP Inference Summary\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  Batch size:           {N_BATCH}\")\n",
    "print(f\"  True shear:           g1={G1_TRUE}, g2={G2_TRUE}\")\n",
    "print(f\"  Inference method:     MAP\")\n",
    "print(f\"  All passed:           {n_passed}/{N_BATCH}\")\n",
    "print(f\"  Mean m(g1):           {m_g1_vals.mean():.2e}\")\n",
    "print(f\"  Mean c(g2):           {c_g2_vals.mean():.2e}\")\n",
    "print(f\"  Max |g1 offset|:      {max(abs(r['g1_est'].mean - G1_TRUE) for r in results):.2e}\")\n",
    "print(f\"  Max |g2 offset|:      {max(abs(r['g2_est'].mean - G2_TRUE) for r in results):.2e}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
